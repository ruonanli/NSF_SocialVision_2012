\subsection{An Integrated Socially-Aware Visual Analytical Framework}

At the current and initial stage of the effort to bring socialized semantics to computer vision, it can be usually the case that we do not have sufficient social contexts to help improving our target/face recognition, and we are not always specific about what are the meaningful social interactive activities that are most informative for social description. Conversely, we may neither know clearly about what exactly we should distill from images to fulfill a network learning task, nor have concrete knowledge about how the multiple views or overlapping community structures of a network will eventually turn out to be. However, we have argued at the beginning and demonstrated through the four proposed research problems the fact that the two aspects assist and benefit from each other, and an overall socially-aware visual analytical system is our ultimate goal. To this end, our final proposed research will include an attempt for a framework that eventually integrate social information and image understanding and allow them to learn self-build themselves in an evolving and unsupervised manner.

While an universally applicable framework or prototype system to accomplish this purpose is a long-term objective that may require more than affordable for the moment, at a reasonably constrained visual scene and a fixed group of social agents of small to medium scale is completely feasible and is on our agenda. We plan, for example, at a later stage of the award period, to move toward such a computer vision system that can reveal the heterogeneous and possibly time-varying social networks of all students that enroll in a semester-long course offered at Harvard University. 

As illustrated by the diagram in Fig. \ref{fig:featurelearn}(b). We will employ the classroom observation system as introduced in Section \ref{sec:activity} as our interface to harvest a volume of video sequences recording the indoor behaviors of the same class of students throughout the semester. The course that they enroll in uses interactive instruction by which they students are self-seated and engage in ad-hocly grouped discussions. We also maintain a teaching database where we have textual metadata regarding the students' profile data, status, learning performance, etc., as initial and partial social contexts among the students. Through the face recognition system introduced in Section \ref{sec:recognition}, we may obtain initial identifications of each human in each scene. Meanwhile, we may detect socially meaningful interactive activities, co-occurrences, as well as compute other low-level visual clues for the purpose of estimating a `noisy' version of a multi-view network representation using the approach in Section \ref{sec:vis2net}, with the unobservable links between pairs in different views robustly reconstructed by the method in Section \ref{sec:reconstruct}. The `hallucinated' social network from the videos in this way then provides the visually-sensed `honest' update for the network prior and is consolidated with the `textual' network as a comprehensive and more accurate characterization of this community. The feedback channel finally infuse the updated social contexts and concepts to the face recognizer and the interaction detector. We expect such a close-loop socially-aware visual analytical framework to shed new lights on the `mystery' that we mentioned at the beginning of this proposal, and to enable our new look at the images and videos in this socially networked era.

