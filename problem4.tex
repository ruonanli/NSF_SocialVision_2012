\subsubsection{Robust Reconstruction of Incomplete Networks}
\label{sec:reconstruct}

A second realistic condition, in particular relevant for our visual sensing paradigm, is that the social networks are usually noisy and partially observed, meaning that not all links/affinities from all views are accurate and `visible'. Some links, i.e., edges in the graph cannot be evaluated with a weight, for example, because of the incapability of the vision function on a particular image, resulting in incomplete graphs.

A practically meaningful representation of social network must accommodate this challenge. In this case, we will ned to re-represent the undirected weighted graph of $K$ nodes as $G$ describing the connections of $K$ members, where $G\triangleq\{A^{(v)}, Q^{(v)}\}, v=1,2,\cdots,V$, $A^{(v)}$ is the $K\times K$ affinity matrix for the $v$th view, and $Q^{(v)}$ is the $K\times K$ visibility matrix for that view. If $Q^{(v)}(i,j)=1$, then $A^{(v)}(i,j)$ is the weight describing the tie or closeness between node $i$ and node $j$ estimated from the $v$th view; otherwise if $Q^{(v)}(i,j)=0$ then $A^{(v)}(i,j)$ is a missing number indicating the lack of information of this link in this view. In the case that the views directly correspond to low-level visual cues, we may imagine that the ties between the pairs of members should not vary among different views due to different sensing modalities, and therefore there exist a unique community structure underlying all views. A primary objective in this case, is that how we may discover the community (clustering) effect from this partially observed multi-view network, together with filling the missing links with a proper weight. We refer to this primary task as network reconstruction.

Obviously, a desirable way to represent the group of $K$ nodes is to find a `view-invariant' representation for them. To this end, we imagine that if each node $i$ in the graph can be uniquely identified with a point $\vx_i$ in an Euclidean space, then the distance between each pair of points $(i,j)$ can be regarded as the `view-invariant' dissimilarity between the two nodes, and the view-specific affinity $A^{(v)}(i,j)$ may be derived from certain view-specific transform of the Euclidean distance between the two points $i$ and $j$. Moreover, the community structure is also easier to be characterized as clustering effect in the Euclidean space, and the observability of the affinities is also straightforward to present through the indicating variable $Q^{(v)}(i,j)$. The question whether all these conjectures can be successful now boils down to the question whether there exists a universal connection between Euclidean distances and arbitrary graph affinities.

The answer is YES. We have proved the following theorem, which implies that arbitrary graph affinities may always be analytically transformed into Euclidean distances between points. The proof of the theorem is based on Multi-Dimensional Scaling (MDS) \cite{CoxMDS}, and is omitted due to space limitation.

\vspace{5pt}
\textbf{Theorem}. \textit{If $A$ is symmetric affinity matrix with all zeros on the diagonal and positive numbers everywhere else, then there exists a constant $c$ such that $(\frac{1}{A(i,j)^2}+c)^{\frac{1}{2}}$ is the Euclidean distance between point $i$ (representing node $i$) and point $j$ (representing node $j$) in an Euclidean space, where $c\geq\lambda$, the smallest eigenvalue of $\Lambda=H\Gamma H$, $H=\mathbf{I}-\frac{\mathbf{1}\mathbf{1}^T}{K}$, and $\Gamma(i,j)=-\frac{1}{2A(i,j)^2}$.} $\blacksquare$
\vspace{5pt}


The above theorem provides theoretical guarantee that each member (node) can be uniquely identified with a point in a Euclidean space, because now the Euclidean embedded nodes $\vx_i$'s and the generic social network representation $G$ are naturally related as
\begin{equation}\label{eq:embed}
d^{(v)}(\vx_i, \vx_j, \theta^{(v)})=(\frac{1}{A^{(v)}(i,j)^2}+c^{(v)})^{\frac{1}{2}}+\epsilon_{ijv}, \forall Q^{(v)}(i,j)=1,
\end{equation}
where $d^{(v)}(\cdot, \cdot, \theta^{(v)})$ is a properly defined distance in the Euclidean space specific to the $v$th view with parameter $\theta^{(v)}$, and $\epsilon$ is a residual. Meanwhile, the community structure, as the social network prior, may consequently  be modeled in the Euclidean space as well, for example, via
\begin{equation}\label{eq:kmeans}
Z=\arg\min_{D,\hat{Z}}\|X-D\hat{Z}\|^{2}_{2}, \textup{s.t.} \hat{Z}^{T}\mathbf{1}=\mathbf{1},
 \end{equation}
where $X=[\vx_1,\vx_2,\cdots,\vx_K]$, each column of $D$ represents the center of a cluster, and $Z, \hat{Z}$ are a binary matrices by which we assign a node to a cluster among the communities of interest given by $D$. Upon learning the overall model incorporating the essential components in (\ref{eq:embed})(\ref{eq:kmeans}). It is straightforward to reconstruct the noisy and the missing affinities through transforms of Euclidean distances, and to investigate the underlying community structure invariant of views.


In fact, identity association (Section \ref{sec:assoc}) and network reconstruction (Section \ref{sec:reconstruct}) can benefit from each other and constitute a close loop for improved social network estimation. Specifically, consider that if a less accurate face recognizer provides weak confidence about identities, and the error is propagated to low-level cues. As a result, the estimated multi-view networks is noisy. By exploiting the `view-invariance' and reconstructing the link affinities, we essentially get a de-noised version of the multi-view network. The enhanced or reduced ties between nodes conversely provide updated implication about the identity association for the two targets in the image/video which contribute to the estimation for the two nodes. In other words, the proposed set of approaches in Section \ref{sec:vis2net} will essentially collaborate together.