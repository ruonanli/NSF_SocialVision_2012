\subsubsection{Noisy and incomplete network reconstruction}
\label{sec:reconstruct}

In many situations, images and videos from which we extract the multi-source cues are of low qualities, human beings are under significant pose variation, occlusion, and clutter, and most importantly, computer vision is imperfect and may frequently be incapable of yielding reliable outcomes for the network estimation to use. Consequently, the effects of invisible (missing) and noisy links, i.e., that an edge in the graph cannot be evaluated with a weighted affinity, will be prevalent in a visually sensed social network. While this scenario is related to the traditional link prediction \cite{Goldberg,Liben-Nowell,TaskarWAK03} and receives initial treatment in network completion \cite{Clauset,Guimera,HannekeX09,KimL11}, we propose to explore better alternatives specific to the multi-view visually sensed network.

As a preliminary approach, we first re-represent the undirected weighted graph of $K$ nodes as $G$ describing the connections of $K$ members, where $G\triangleq\{A^{(v)}, Q^{(v)}\}, v=1,2,\cdots,V$, $A^{(v)}$ is the $K\times K$ affinity matrix for the $v$th view, and $Q^{(v)}$ is the $K\times K$ visibility matrix for that view. If $Q^{(v)}(i,j)=1$, then $A^{(v)}(i,j)$ is the weight describing the tie or closeness between node $i$ and node $j$ estimated from the $v$th view; otherwise if $Q^{(v)}(i,j)=0$ then $A^{(v)}(i,j)$ is a missing number indicating the lack of information of this link in this view. Our objective is to fill the missing links ($Q^{(v)}(i,j)=0$) with a proper weight for this partially observed multi-view network. 

%In the case that the views directly correspond to low-level visual cues, we may imagine that the ties between the pairs of members should not vary among different views due to different sensing modalities, and therefore there exist a unique community structure underlying all views. A primary objective in this case, is that how we may discover the community (clustering) effect from this partially observed multi-view network, together with filling the missing links with a proper weight. We refer to this primary task as network reconstruction.

The multi-view representation implies to exploit the mutual contexts provided from one view to another view. One may imagine that if the invisibles and gross errors are incoherent across views, visible and reliable affinities from other views will embed important information about this noisy view, and one may even find a `view-invariant' representation for the different views. To this end, we imagine that if each node $i$ in the graph can be uniquely identified with a point $\vx_i$ in an Euclidean space, then the distance between each pair of points $(i,j)$ in that space can be regarded as the `view-invariant' dissimilarity between the two nodes, and the view-specific affinity $A^{(v)}(i,j)$ may be derived from certain view-specific transform of the Euclidean distance. The question whether these conjectures can be successful now boils down to the question whether there exists a universal connection between Euclidean distances and arbitrary graph affinities.

The answer is YES. We have proved the following theorem, which implies that arbitrary graph affinities may always be analytically transformed into Euclidean distances between points. The proof is based on Multi-Dimensional Scaling \cite{CoxMDS}, and is omitted due to space limitation.

\vspace{5pt}
\textbf{Theorem}. \textit{If $A$ is symmetric affinity matrix with all zeros on the diagonal and positive numbers everywhere else, then there exists a constant $c$ such that $(\frac{1}{A(i,j)^2}+c)^{\frac{1}{2}}$ is the Euclidean distance between point $i$ (representing node $i$) and point $j$ (representing node $j$) in an Euclidean space, where $c\geq\lambda$, the smallest eigenvalue of $\Lambda=H\Gamma H$, $H=\mathbf{I}-\frac{\mathbf{1}\mathbf{1}^T}{K}$, and $\Gamma(i,j)=-\frac{1}{2A(i,j)^2}$.} 
\vspace{5pt}


The above theorem provides theoretical guarantee that each member (node) can be uniquely identified with a point in a Euclidean space, because now the Euclidean embedded nodes $\vx_i$'s and the generic social network representation $G$ are naturally related as
\begin{equation}\label{eq:embed}
(\vx_i-\vx_j)^{T}\Sigma^{(v)}(\vx_i-\vx_j)=\left(\frac{1}{A^{(v)}(i,j)^2}+c^{(v)}\right)^{\frac{1}{2}}+\epsilon^{(v)}_{ij}, \forall Q^{(v)}(i,j)=1,
\end{equation}
where $\Sigma^{(v)}$ is a symmetric semi-positive definite matrix specific to the $v$th view and $\epsilon$ is a residual. The technique that we adopt is new when compared to existing embedding ideas \cite{Hoff01latentspace,Hancocklatent}, multi-view networks \cite{AiroldiBFX08,Kim12}, and network completion \cite{Clauset,Guimera,HannekeX09,KimL11}, because it seamlessly unifies Eucliean embedding, multi-views, and missing data together, and more effectively exploits mutual contexts among view rather than other generic network constraints, which has not been attempted by existing social network research. In fact, any application-dependent network priors or regularizations are straightforward to be characterized through the embedded points $\vx_i$. 


%A unified community clustering effect, as the social network prior, may consequently  be modeled in the Euclidean space as well, for example, via
%\begin{equation}\label{eq:kmeans}
%Z=\arg\min_{D,\hat{Z}}\|X-D\hat{Z}\|^{2}_{2}, \textup{s.t.} \hat{Z}^{T}\mathbf{1}=\mathbf{1},
% \end{equation}
%where $X=[\vx_1,\vx_2,\cdots,\vx_K]$, each column of $D$ represents the center of a cluster, and $Z, \hat{Z}$ are a binary matrices by which we assign a node to a cluster among the communities of interest given by $D$. Upon learning the overall model incorporating the essential components in (\ref{eq:embed})(\ref{eq:kmeans}). It is straightforward to reconstruct the noisy and the missing affinities through transforms of Euclidean distances, and to investigate the underlying community structure invariant of views.

\subsubsection{Closing the loop}
\label{sec:closeloop}

A significant distinction of our framework, is that the modules naturally collaborate with each other and previous techniques. Identity association (Section \ref{sec:assoc}) and network reconstruction (Section \ref{sec:reconstruct}), in fact, benefit from each other and constitute a close loop for improved social network estimation. If a less accurate face recognizer provides weak confidence about identities, the error will be propagated to low-level cues $\vy$. As a result, the estimated multi-view networks is noisy. However by reconstructing the affinities, we essentially get a de-noised version of the multi-view network. The denoised ties between nodes conversely provide improved implication about the correct identity association with image targets, which may essentially be achieved via PI Zickler's previous work on joint face recognition using social contexts \cite{Stone2008,Stone2010} or its adapted version. \comment{In other words, the proposed set of approaches in Section \ref{sec:vis2net} will essentially collaborate together.}
